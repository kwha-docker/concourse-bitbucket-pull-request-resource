#!/usr/bin/env python3

import subprocess
import os
import sys
import json
import traceback
import collections
import yaml
from bitbucket import (
    json_pp, err, request_access_token, get_prs, BitbucketException, get_diff
)
from utils import greater_than_days_cutoff

# Concourse prefer dictionaries in arrays as output with name
# value pairings
def reformat(key, value):
    return {
        "name": str(key),
        "value": str(value)
    }

# Helper function to ensure only strings are present since unicode
# presents errors
def convert(data):
    if isinstance(data, str):
        return str(data)
    elif isinstance(data, collections.Mapping):
        return dict(map(convert, data.items()))
    elif isinstance(data, collections.Iterable):
        return type(data)(map(convert, data))
    else:
        return data

j = json.loads("".join(sys.stdin.readlines()))
j = convert(j)

debug = j['source'].get('debug', False)

if debug:
    err(j)

if debug:
    err("--DEBUG MODE--")

# Configuration vars
project = j['source']['project']
repo = j['source']['repo']
client_id = j['source']['client_id']
secret = j['source']['secret']
all_prs = j['source'].get('all_prs', False)
state = j['source'].get('state', 'OPEN')
pages = j['source'].get('pages', 3)
pagelen = j['source'].get('pagelen', 50)
diff = j['source'].get('return_diff', False)
time_cutoff = j['source'].get('time_cutoff', 14) # Number of days for cutoff

# Version vars
version = j['version']
pr_no = version['pr_no']

output_dir = sys.argv[1]
if debug:
    err(output_dir)

# Get the access token for the repo and get the open PRs
try:
    access_token = request_access_token(client_id, secret, debug)
    if all_prs:
        # Use pagination
        pr_request, request_count = get_prs(project, repo, access_token,
                                            debug, state=state, next_page=True,
                                            pages=pages, pagelen=pagelen)
        prs = pr_request
    else:
        pr_request, request_count = get_prs(project, repo, access_token, debug, pr_no=pr_no)
        prs = [pr_request]
except BitbucketException:
    traceback.print_exc()
    err(str(e))
    exit(1)

metadata = []
pr_list = []
# If processing all prs in the list, put the prs
# in a list of lists to write out to a file
if all_prs:
    for data in prs[::-1]:

        # Check PR is not older than cutoff
        if greater_than_days_cutoff(data['updated_on'], time_cutoff):
            err('PR {} latest update is older than {} days. Not passing down.'
                .format(data['id'], time_cutoff))
            continue

        pr = []
        pr.append(reformat("author", data["author"]["display_name"]))
        pr.append(reformat("source", data["source"]["branch"]["name"]))
        pr.append(reformat("destination", data["destination"]["branch"]["name"]))
        pr.append(reformat("commit", data['source']['commit']['hash'][:16]))
        pr.append(reformat("username", data['author']['nickname'].replace(' ', '-')))
        pr.append(reformat("url", data['links']['html']['href']))
        pr.append(reformat("pr_no", data['id']))
        pr.append(reformat("repo", data['source']['repository']['name']))
        pr.append(reformat("state", data['state']))

        # Obtain the diff count if specified
        if diff:
            content, files_changed = get_diff(project, repo, access_token, data['id'])
            pr.append(reformat("diff", len(content)))
            pr.append(reformat("files_changed", files_changed))

        pr_list.append(pr)
    # We still need a resultant written to stdout
    # so record that here
    for val in pr_list[-1]:
        metadata.append(val)
# If we are not processing all prs, we are just processing
# the most recent
else:
    for data in prs:
        metadata.append(reformat("author", data["author"]["display_name"]))
        metadata.append(reformat("source", data["source"]["branch"]["name"]))
        metadata.append(reformat("destination", data["destination"]["branch"]["name"]))
        metadata.append(reformat("commit", data['source']['commit']['hash'][:16]))
        metadata.append(reformat("username", data['author']['nickname'].replace(' ', '-')))
        metadata.append(reformat("url", data['links']['html']['href']))
        metadata.append(reformat("repo", data['source']['repository']['name']))
        metadata.append(reformat("state", data['state']))
        if diff:
            content, files_changed = get_diff(project, repo, access_token, data['id'])
            metadata.append(reformat("diff", len(content)))
            metadata.append(reformat("files_changed", files_changed))


# Write out the result to stdout
result = {
    "version": version,
    "metadata": metadata
    }

if debug:
    err(json.dumps(result, indent=2))
    err(json.dumps(version, indent=2))

sys.stdout.write(json.dumps(result))

# Write out the version information in a yaml file
with open(os.path.join(output_dir, "version.yaml"), "w") as fp:
    print(yaml.dump(result, default_flow_style=False), file=fp)

if all_prs:
    err(len(pr_list))
    pr_path = os.path.join(output_dir, 'prs')
    os.mkdir(pr_path)
    with open(os.path.join(pr_path, "prs.yaml"), "w") as fp:
        print(yaml.dump(pr_list, default_flow_style=False), file=fp)
